# rag/core/pipeline.py
# -*- coding: utf-8 -*-
"""
RAGPipeline: ç»“åˆä¸»è®°å¿† + è¾…åŠ©è®°å¿† + çŸ¥è¯†åº“ï¼ˆé¢„ç•™ï¼‰
- run(): ç»™å®š queryï¼Œæ‹¼æ¥ä¸Šä¸‹æ–‡ï¼Œè°ƒç”¨ LLMï¼Œè¿”å›ç­”æ¡ˆ
"""
import json
import re
from typing import Dict, Any, List
from rag.datasource.base import Datasource
from rag.memory.memory_manager import MemoryManager
from rag.llm.providers.openai_client import OpenAIClient
from rag.core.retriever_jd import JDRetriever

class RAGPipeline:
    def __init__(self, ds: Datasource, memory: MemoryManager, llm: OpenAIClient):
        """
        :param ds: Datasource å®ä¾‹ï¼ˆå°è£… minio / weaviate / registry / primary / contextsï¼‰
        :param memory: MemoryManager å®ä¾‹
        :param llm: LLM å®¢æˆ·ç«¯ï¼ˆé»˜è®¤ç”¨ OpenAIClientï¼Œå¯æ¢ï¼‰
        """
        self.ds = ds
        self.memory = memory
        self.llm = llm

    def _fetch_texts(self, urls: List[str]) -> List[str]:
        """
        ä» MinIO æ‹‰å–ä¸€æ‰¹ url å¯¹åº”çš„æ­£æ–‡
        """
        texts = []
        for url in urls:
            try:
                texts.append(self.ds.minio.get_text(url))
            except Exception as e:
                texts.append(f"[è¯»å–å¤±è´¥: {url}, é”™è¯¯: {e}]")
        return texts

    def run(
        self,
        memory_id: str,
        app: str,
        query: str,
        summary_k: int = 1,
        recent_k: int = 6,
        aux_top_k: int = 5,
        aux_threshold: float = None,
        max_chars: int = 4000,
    ) -> Dict[str, Any]:
        """
        è¿™ä¸ªå‡½æ•°æ˜¯åªç»“åˆè®°å¿†èƒ½åŠ›å›ç­”ç”¨æˆ·çš„é—®é¢˜
        æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„ RAG æ¨ç†ï¼š
        1) è°ƒç”¨ MemoryManager è·å–ä¸Šä¸‹æ–‡ï¼ˆä¸»è®°å¿† + è¾…åŠ©è®°å¿†ï¼‰
        2) ä» MinIO æ‹‰å–æ­£æ–‡
        3) æ‹¼æ¥ä¸Šä¸‹æ–‡ï¼ˆæœ‰ token/å­—ç¬¦é™åˆ¶ï¼‰
        4) è°ƒç”¨ LLM ç”Ÿæˆå›ç­”

        :return: { "answer": str, "context_used": dict }
        """
        # 1) ä»è®°å¿†æ¨¡å—è·å–ä¸Šä¸‹æ–‡
        ctx = self.memory.get_context(
            memory_id=memory_id,
            app=app,
            query=query,
            summary_k=summary_k,
            recent_k=recent_k,
            aux_top_k=aux_top_k,
            aux_threshold=aux_threshold,
        )
        # print(ctx)

        # 2) æ‹‰å–æ‘˜è¦å’Œæœ€è¿‘æ¶ˆæ¯çš„æ­£æ–‡
        texts = []
        texts.extend(self._fetch_texts(ctx.get("summary_urls", [])))
        texts.extend(self._fetch_texts(ctx.get("recent_urls", [])))

        # 3) åŠ ä¸Šè¾…åŠ©è®°å¿†æ£€ç´¢åˆ°çš„å†…å®¹
        for hit in ctx.get("retrieved", []):
            texts.append(hit["content"])

        # print(" texts", texts)
        # 4) æ‹¼æ¥ä¸Šä¸‹æ–‡ï¼ˆåŠ é•¿åº¦é™åˆ¶ï¼‰
        context = ""
        for t in texts:
            if len(context) + len(t) > max_chars:
                break
            context += "\n\n" + t

        # 5) æ„é€  prompt å¹¶è°ƒç”¨ LLM
        prompt = (
            f"ä»¥ä¸‹æ˜¯ä¸ç”¨æˆ·ç›¸å…³çš„å†å²å¯¹è¯ä¸ä¿¡æ¯ï¼Œè¯·ç»“åˆå®ƒä»¬å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n"
            f"--- ä¸Šä¸‹æ–‡å¼€å§‹ ---\n{context}\n--- ä¸Šä¸‹æ–‡ç»“æŸ ---\n\n"
            f"ç”¨æˆ·é—®é¢˜ï¼š{query}\nè¯·ç”¨ç®€æ´ã€å‡†ç¡®çš„æ–¹å¼å›ç­”ã€‚"
        )

        answer = self.llm.complete(
            prompt,
            temperature=0.3,
            top_p=1.0,
            max_tokens=800,
            system="ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„åŠ©æ‰‹ï¼Œä¼šç»“åˆå†å²ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
        )

        return {
            "answer": answer,
            "context_used": ctx
        }

    def generate_interview_questions(
            self,
            memory_id: str,
            app: str,
            resume_url: str | None = None,
            jd_id: str | None = None,
            company: str | None = None,
            target_position: str | None = None,
            jd_top_k: int = 1,
            memory_top_k: int = 3,
            max_chars: int = 500,
    ):
        """
        é¢è¯•å®˜åœºæ™¯ï¼ˆæ”¹è¿›ç‰ˆï¼‰ï¼š
        ------------------------------------------------
        åŸºäºå€™é€‰äººç®€å† + å²—ä½JD + å†å²ä¸Šä¸‹æ–‡ï¼Œ
        åˆ†ä¸‰æ­¥ç”Ÿæˆä¸‰ç±»é—®é¢˜ï¼ˆåŸºç¡€é¢˜ / é¡¹ç›®é¢˜ / åœºæ™¯é¢˜ï¼‰ï¼Œ
        å„è‡ªç‹¬ç«‹è°ƒç”¨ LLMï¼Œå†æ±‡æ€»æˆ9é“é«˜è´¨é‡é¢è¯•é¢˜ã€‚
        """

        # 1ï¸âƒ£ æ‹‰å–å€™é€‰äººç®€å†å†…å®¹
        resume_data = {}
        if resume_url:
            try:
                resume_text = self.ds.minio.get_text(resume_url)
                resume_data = json.loads(resume_text)
            except Exception as e:
                resume_data = {"error": f"è¯»å–ç®€å†å¤±è´¥: {str(e)}"}

        # 2ï¸âƒ£ è·å–è®°å¿†ä¸Šä¸‹æ–‡
        ctx = self.memory.get_context(
            memory_id=memory_id,
            app=app,
            query=target_position or "é¢è¯•ç”Ÿæˆ",
            recent_k=memory_top_k,
            summary_k=1
        )
        texts = []
        texts.extend(self._fetch_texts(ctx.get("summary_urls", [])))
        texts.extend(self._fetch_texts(ctx.get("recent_urls", [])))
        for hit in ctx.get("retrieved", []):
            texts.append(hit["content"])
        context = "\n\n".join(texts)[:max_chars]

        # 3ï¸âƒ£ è·å– JD å†…å®¹ï¼ˆä¼˜å…ˆç”¨æˆ·ä¸Šä¼ çš„ JDï¼‰
        jd_context = ""
        if jd_id:
            try:
                row = self.ds.uploaded_jd.get(jd_id, memory_id)
                print("row:", row)
                if row:
                    company = row.get("company") or company  # âœ… è‡ªåŠ¨è¦†ç›–
                    target_position = row.get("position") or target_position
                    jd_context = row.get("content") or ""
                    print(f"âœ… ä½¿ç”¨ç”¨æˆ·ä¸Šä¼ çš„JDï¼š{jd_id} ({company or ''} - {target_position or ''})")
                else:
                    jd_context = "[æœªæ‰¾åˆ°ä¸Šä¼ çš„JD]"
                    print(f"âš ï¸ æœªæ‰¾åˆ° jd_id={jd_id} å¯¹åº”JDè®°å½•ï¼Œå›é€€è‡³JDåº“æ£€ç´¢ã€‚")
                    retriever = JDRetriever(collection="InterviewerJDKnowledge", company=company)
                    jd_hits = retriever.search(target_position or "é€šç”¨é¢è¯•", top_k=jd_top_k)
                    jd_context = "\n".join([
                        f"å²—ä½è¦æ±‚ï¼š{h['requirements']}\næè¿°ï¼š{h['description']}"
                        for h in jd_hits
                    ])[:max_chars]
            except Exception as e:
                print(f"âš ï¸ è¯»å–ç”¨æˆ·ä¸Šä¼ JDå¤±è´¥: {e}")
                jd_context = f"[JDè¯»å–å¤±è´¥: {e}]"
        else:
            # ğŸ” åŸé€»è¾‘ï¼šJDå‘é‡åº“æ£€ç´¢
            print("# ğŸ” åŸé€»è¾‘ï¼šJDå‘é‡åº“æ£€ç´¢")
            retriever = JDRetriever(collection="InterviewerJDKnowledge", company=company)
            jd_hits = retriever.search(target_position or "é€šç”¨é¢è¯•", top_k=jd_top_k)
            jd_context = "\n".join([
                f"å²—ä½è¦æ±‚ï¼š{h['requirements']}\næè¿°ï¼š{h['description']}"
                for h in jd_hits
            ])[:max_chars]


        # 4ï¸âƒ£ é€šç”¨åŸºç¡€ä¿¡æ¯å—
        base_info = f"""
    èŒä½ï¼š{resume_data.get('position', '')}
    æŠ€èƒ½ï¼š{', '.join(resume_data.get('skills', []))}
    é¡¹ç›®ç»å†ï¼š
    {chr(10).join(resume_data.get('projects', []))}

    å†å²é¢è¯•ä¸Šä¸‹æ–‡ï¼š
    {context}

    å²—ä½ä¿¡æ¯ï¼ˆJDï¼‰ï¼š
    {jd_context}
    """

        # ---------------------------------------------------------------------
        # 5ï¸âƒ£ ä¸‰ç±»é¢˜å‹ Prompt æ„é€ 
        # ---------------------------------------------------------------------

        # (1) åŸºç¡€çŸ¥è¯†ä¸æŠ€èƒ½é¢˜
        basic_prompt = f"""
    ä½ æ˜¯ä¸€åèµ„æ·±æŠ€æœ¯é¢è¯•å®˜ï¼Œè¯·æ ¹æ®å€™é€‰äººç®€å†ä¸­çš„æŠ€èƒ½åˆ—è¡¨ï¼Œ
    ç”Ÿæˆä¸‰é“åŸºç¡€çŸ¥è¯†ä¸æŠ€èƒ½ç±»é¢è¯•é¢˜ã€‚

    è¦æ±‚ï¼š
    - æ¯é¢˜å¿…é¡»ç›´æ¥åŸºäºå€™é€‰äººç®€å†ä¸­æåˆ°çš„å…·ä½“æŠ€æœ¯ï¼ˆå¦‚ SpringBootã€Redisã€Kafkaã€Flinkã€Dockerã€MyBatisã€WebSocket ç­‰ï¼‰ï¼›
    - è€ƒå¯Ÿå€™é€‰äººå¯¹æŠ€æœ¯åŸç†ã€æ¶æ„è®¾è®¡ã€æ€§èƒ½ä¼˜åŒ–çš„ç†è§£ï¼›
    - é—®é¢˜åº”å…·ä½“ã€æœ‰æ·±åº¦ï¼›
    - ä¸¥æ ¼è¾“å‡º JSON æ ¼å¼ï¼Œå­—æ®µåä¸º "questions"ã€‚
    
    ã€å€™é€‰äººä¿¡æ¯ã€‘
    {base_info}
    
    ã€è¾“å‡ºç¤ºä¾‹ã€‘
        {{
          "questions": [
            "åœ¨ä½ ç†Ÿæ‚‰çš„ SpringBoot æŠ€æœ¯æ ˆä¸­ï¼Œç³»ç»Ÿå¦‚ä½•åŒæ—¶é›†æˆ Redisã€Kafka å’Œ RabbitMQï¼Ÿè¯·è¯¦ç»†è¯´æ˜ï¼Œåœ¨é«˜å¹¶å‘ä¸‹çš„æ¶ˆæ¯ä¸€è‡´æ€§ä¸äº‹åŠ¡ä¿éšœæœºåˆ¶",
            ...
          ]
        }}
    """

        # (2) é¡¹ç›®ç»éªŒé¢˜
        project_prompt = f"""
    ä½ æ˜¯ä¸€åèµ„æ·±ç³»ç»Ÿæ¶æ„é¢è¯•å®˜ï¼Œè¯·ä»”ç»†é˜…è¯»å€™é€‰äººç®€å†ä¸­çš„é¡¹ç›®ç»å†ï¼Œ
    é’ˆå¯¹æ¯ä¸ªé¡¹ç›®ç”Ÿæˆä¸€åˆ°ä¸¤é“æ·±å…¥æŒ–æ˜é¡¹ç›®ç»†èŠ‚çš„é¢è¯•é¢˜ï¼Œä¸€å…±ä¸‰é“é¢˜ã€‚

    è¦æ±‚ï¼š
    - æ¯é¢˜å¿…é¡»å¼•ç”¨é¡¹ç›®åç§°ï¼›
    - æ˜ç¡®è€ƒå¯Ÿå€™é€‰äººé¡¹ç›®ä¸­çš„è®¾è®¡æ€è·¯ã€æŠ€æœ¯å®ç°ã€æ€§èƒ½ä¼˜åŒ–æˆ–ç³»ç»Ÿç¨³å®šæ€§ï¼›
    - ä¼˜å…ˆç»“åˆç®€å†ä¸­å‡ºç°çš„å…·ä½“æŠ€æœ¯ï¼ˆå¦‚ Flinkã€Kafkaã€Redisã€WebSocket ç­‰ï¼‰ï¼›
    - é—®é¢˜è¦è¶³å¤Ÿè¯¦ç»†ã€å…·ä½“ï¼›
    - ä¸¥æ ¼è¾“å‡º JSON æ ¼å¼ã€‚

    ã€å€™é€‰äººé¡¹ç›®ç»å†ã€‘
    {base_info}
    
    ã€è¾“å‡ºç¤ºä¾‹ã€‘
        {{
          "questions": [
            "åœ¨ä½ è´Ÿè´£çš„â€œæ™ºæ…§è¥é”€ä½œä¸šå¹³å°â€é¡¹ç›®ä¸­ï¼Œä½ æåˆ°ä½¿ç”¨äº† Flink ä¸ Kafka è¿›è¡Œå®æ—¶æ•°æ®æµå¤„ç†ã€‚è¯·è¯¦ç»†è¯´æ˜è¯¥ç³»ç»Ÿçš„æµå¼æ¶æ„è®¾è®¡",
            ...
        ]
        }}
    """

        # (3) åœºæ™¯åˆ†æé¢˜
        scenario_prompt = f"""
    ä½ æ˜¯ä¸€åä¼ä¸šæŠ€æœ¯é¢è¯•å®˜ï¼Œè¯·æ ¹æ®å²—ä½æè¿°ï¼ˆJDï¼‰ä¸å€™é€‰äººç®€å†ä¿¡æ¯ï¼Œ
    ç”Ÿæˆä¸‰é“åœºæ™¯åˆ†æé¢˜ï¼Œç”¨äºè€ƒå¯Ÿå€™é€‰äººåº”å¯¹å®é™…é—®é¢˜çš„èƒ½åŠ›ã€‚

    è¦æ±‚ï¼š
    - æ¯é¢˜æè¿°ä¸€ä¸ªçœŸå®ä¸šåŠ¡åœºæ™¯,ä¸šåŠ¡åœºæ™¯è¦è¶³å¤Ÿè¯¦ç»†æ¸…æ™°ï¼Œè®©å€™é€‰äººåˆ†æé—®é¢˜ä¸è§£å†³æ–¹æ¡ˆï¼›
    - é—®é¢˜åº”ç»“åˆå€™é€‰äººé¡¹ç›®èƒŒæ™¯ä¸æŠ€æœ¯æ ˆï¼›
    - ä¸¥æ ¼è¾“å‡º JSON æ ¼å¼ã€‚

    ã€å²—ä½ä¿¡æ¯ï¼ˆJDï¼‰ã€‘
    {jd_context}

    ã€å€™é€‰äººç®€å†æ‘˜è¦ã€‘
    {base_info}
    
    ã€è¾“å‡ºç¤ºä¾‹ã€‘
        {{
          "questions": [
            "å‡è®¾ä½ åœ¨â€œä¼ä¸šæ™ºèƒ½å®¢æœå¹³å°â€é¡¹ç›®ä¸­é‡åˆ°å¦‚ä¸‹åœºæ™¯ï¼šç³»ç»Ÿæ¯æ—¥å¤„ç†ä¸Šç™¾ä¸‡æ¬¡ç”¨æˆ·æ¶ˆæ¯è¯·æ±‚ï¼›WebSocket é•¿è¿æ¥é¢‘ç¹æ–­å¼€ï¼›Redis ç¼“å­˜å‘½ä¸­ç‡é™ä½ï¼Œå“åº”æ—¶é—´ä¸Šå‡ã€‚è¯·åˆ†æï¼šå¯èƒ½çš„æ€§èƒ½ç“¶é¢ˆæ¥æºï¼›å¦‚ä½•åœ¨æœåŠ¡ç«¯æ¶æ„ä¸Šæ”¹è¿›ï¼ˆåŒ…æ‹¬è¿æ¥ç®¡ç†ã€ç¼“å­˜ç­–ç•¥ä¸å¼‚æ­¥ä»»åŠ¡è®¾è®¡ï¼‰ï¼›",
            ...
          ]
        }}
    """

        # ---------------------------------------------------------------------
        # 6ï¸âƒ£ ä¸‰æ¬¡ç‹¬ç«‹è°ƒç”¨ LLM
        # ---------------------------------------------------------------------
        def _ask_llm(prompt, temperature=0.4, max_tokens=600):
            return self._extract_questions(
                self.llm.complete(
                    prompt,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    system="ä½ æ˜¯ä¸€åé¢è¯•å®˜åŠ©æ‰‹ï¼Œåªè¾“å‡ºJSONæ ¼å¼çš„é¢˜ç›®ï¼Œä¸è§£é‡Šã€‚"
                )
            )

        basic_questions = _ask_llm(basic_prompt, temperature=0.3)
        project_questions = _ask_llm(project_prompt, temperature=0.5)
        scenario_questions = _ask_llm(scenario_prompt, temperature=0.6)

        # ---------------------------------------------------------------------
        # 7ï¸âƒ£ æ±‡æ€»ç»“æœ
        # ---------------------------------------------------------------------
        all_questions = basic_questions + project_questions + scenario_questions
        all_questions = [q for q in all_questions if q.strip()]  # æ¸…ç†ç©ºé¡¹

        return {
            "questions": all_questions[:9],
            "context_used": {
                "memory_context": ctx,
                "jd_context_preview": jd_context[:500],
                "resume_url": resume_url,
                "num_basic": len(basic_questions),
                "num_project": len(project_questions),
                "num_scenario": len(scenario_questions)
            }
        }

    def _extract_questions(self, text: str) -> list[str]:
        """è§£æ LLM è¾“å‡ºä¸ºé¢˜ç›®åˆ—è¡¨ï¼ˆæ”¯æŒ JSON + æ–‡æœ¬ä¸¤ç§æ ¼å¼ï¼‰"""
        text = text.strip()

        # âœ… ä¼˜å…ˆå°è¯• JSON è§£æ
        try:
            data = json.loads(text)
            if isinstance(data, dict) and "questions" in data:
                q_list = data["questions"]
                if isinstance(q_list, list):
                    return [q.strip() for q in q_list if isinstance(q, str) and len(q.strip()) > 2]
        except Exception:
            pass

        # âš™ï¸ å›é€€æ–¹æ¡ˆï¼šé€è¡Œæå–ï¼ˆé€‚é… markdown / ç¼–å·æ ¼å¼ï¼‰
        lines = re.findall(r"[-â€¢]?\s*\d*[\.\)]?\s*(.+)", text)
        clean = [l.strip() for l in lines if 4 < len(l.strip()) < 200]
        return clean[:10]  # é™åˆ¶æœ€å¤š10ä¸ªé¢˜ç›®